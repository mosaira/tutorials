{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "nlp_workshop.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mosaira/tutorials/blob/master/nlp_workshop.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_5yvufkDa-HE",
        "colab_type": "text"
      },
      "source": [
        "# 1. spaCy basics"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Mr7ukwtya-HI",
        "colab_type": "text"
      },
      "source": [
        "spaCy is an open-source software library for advanced natural language processing, written in the programming languages Python and Cython.The library is published under the MIT license and currently offers statistical neural network models for English, German, Spanish, Portuguese, French, Italian, Dutch and multi-language NER, as well as tokenization for various other languages.$^{1}$\n",
        "\n",
        "https://spacy.io/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKy5UJqpa-HK",
        "colab_type": "text"
      },
      "source": [
        "## Installation and setup \n",
        "\n",
        "1. First we need to download the spaCy library:\n",
        "    > `conda install -c conda-forge spacy`\n",
        "    > <br>*or*<br>\n",
        "    > `pip install -U spacy`\n",
        "2. Then, we download the language model we want to use:\n",
        "    > `python -m spacy download en_core_web_lg`\n",
        "    > <br>*alternatively*<br>\n",
        "    > `import spacy.cli` <br>\n",
        "    >  `spacy.cli.download(\"en_core_web_lg\") `\n",
        "3. Finally, you load the model:\n",
        "    > `spacy.load('en_core_web_lg')`\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IWLYN-Nga-HL",
        "colab_type": "code",
        "outputId": "a682cd57-af74-4b11-a34c-d7d08ffb67cf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "import spacy.cli\n",
        "spacy.cli.download(\"en_core_web_lg\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_lg')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "be0YyDFSa-HS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Import spaCy\n",
        "import spacy\n",
        "\n",
        "# load the language model\n",
        "nlp = spacy.load('en_core_web_lg')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4zyqq9oa-HX",
        "colab_type": "code",
        "outputId": "1e4aa587-9aa9-4c8b-a54b-d7e93650cbbf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        }
      },
      "source": [
        "# Create a Doc object\n",
        "doc = nlp(u\"The quick brown fox jumps over the lazy dog!\")\n",
        "\n",
        "# Print each token separately\n",
        "for token in doc:\n",
        "    print(token.text, token.pos_, token.dep_)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The DET det\n",
            "quick ADJ amod\n",
            "brown ADJ amod\n",
            "fox NOUN nsubj\n",
            "jumps VERB ROOT\n",
            "over ADP prep\n",
            "the DET det\n",
            "lazy ADJ amod\n",
            "dog NOUN pobj\n",
            "! PUNCT punct\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yExc1Uyca-Hc",
        "colab_type": "code",
        "outputId": "7d4a4343-9414-42de-cabb-fe0ca5e51eb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Get a description for a given POS tag, dependency label or entity type\n",
        "\n",
        "spacy.explain('PUNCT')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'punctuation'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "baxxoL1Va-Hg",
        "colab_type": "text"
      },
      "source": [
        "___\n",
        "## Pipeline\n",
        "When we call `nlp` on our string, we are creating a `DOC` object which is \n",
        "basically an array of token objects made from that string. We can then perform a series of operations on that tokens in order to dercribe the data.   <br>Image source: https://spacy.io/usage/spacy-101#pipelines"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gYotu8M1a-Hi",
        "colab_type": "text"
      },
      "source": [
        "<img src=\"img/pipeline1.png\" width=\"600\">"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xteY87Kna-Hj",
        "colab_type": "code",
        "outputId": "ef2ba50a-ef57-4909-824a-284f4af53240",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "nlp.pipeline"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('tagger', <spacy.pipeline.pipes.Tagger at 0x7f97ea053b00>),\n",
              " ('parser', <spacy.pipeline.pipes.DependencyParser at 0x7f97e9faea68>),\n",
              " ('ner', <spacy.pipeline.pipes.EntityRecognizer at 0x7f97e9faeac8>)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AcBK_w_qa-Ho",
        "colab_type": "text"
      },
      "source": [
        "## Tokenization\n",
        "\n",
        "This is usually the first step in Natural Language Processing. Tokenization means 'chopping' the text into pieces in order to create tokens. Since we are using spaCy with a pretrained language model, these tokens also contain some descriptive information."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1dXvejxda-Hq",
        "colab_type": "code",
        "outputId": "be27db72-a095-456c-c21b-634258cc4e77",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# basic tokenization with a split() function\n",
        "text = \"While Amazon CEO Jeff Bezos wasn't throwing a lavish party at his $23 million mansion in Washington, DC\"\n",
        "print(text.split())"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['While', 'Amazon', 'CEO', 'Jeff', 'Bezos', \"wasn't\", 'throwing', 'a', 'lavish', 'party', 'at', 'his', '$23', 'million', 'mansion', 'in', 'Washington,', 'DC']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RCRxz1COa-Hu",
        "colab_type": "code",
        "outputId": "e8681610-cf03-46a5-d94b-ff77fec0c1a1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        }
      },
      "source": [
        "doc = nlp(text)\n",
        "for token in doc:\n",
        "    print(token.text + \" token.text\", token.pos_+ \" token.post\", token.dep_ + \" token.dep\")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "While token.text ADP token.post mark token.dep\n",
            "Amazon token.text PROPN token.post compound token.dep\n",
            "CEO token.text PROPN token.post compound token.dep\n",
            "Jeff token.text PROPN token.post compound token.dep\n",
            "Bezos token.text PROPN token.post nsubj token.dep\n",
            "was token.text VERB token.post aux token.dep\n",
            "n't token.text ADV token.post neg token.dep\n",
            "throwing token.text VERB token.post ROOT token.dep\n",
            "a token.text DET token.post det token.dep\n",
            "lavish token.text ADJ token.post amod token.dep\n",
            "party token.text NOUN token.post dobj token.dep\n",
            "at token.text ADP token.post prep token.dep\n",
            "his token.text DET token.post poss token.dep\n",
            "$ token.text SYM token.post quantmod token.dep\n",
            "23 token.text NUM token.post compound token.dep\n",
            "million token.text NUM token.post nummod token.dep\n",
            "mansion token.text NOUN token.post pobj token.dep\n",
            "in token.text ADP token.post prep token.dep\n",
            "Washington token.text PROPN token.post pobj token.dep\n",
            ", token.text PUNCT token.post punct token.dep\n",
            "DC token.text PROPN token.post appos token.dep\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PiMorQ14a-H1",
        "colab_type": "text"
      },
      "source": [
        "For a full list of `Part Of Speech` Tags visit https://spacy.io/api/annotation#pos-tagging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VDpQ8ZEna-H3",
        "colab_type": "text"
      },
      "source": [
        "Notice how `wasn't` has been split into two tokens. spaCy recognizes both the root verb is and the negation attached to it. Notice also that both the extended whitespace and the period at the end of the sentence are assigned their own tokens"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xn0_ejCHa-H5",
        "colab_type": "text"
      },
      "source": [
        "Tokens are pieces of the original text. That is, we don't see any conversion to word stems or lemmas (base forms of words) and we haven't seen anything about organizations/places/money etc. Tokens are the basic building blocks of a Doc object - everything that helps us understand the meaning of the text is derived from tokens and their relationship to one another."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3cKmFAm4a-H6",
        "colab_type": "text"
      },
      "source": [
        "___\n",
        "#### Dependencies\n",
        "We also see the syntactic dependencies assigned to each token. `Bezos` is identified as an `nsubj` or the ***nominal subject*** of the sentence.\n",
        "\n",
        "For a full list of Syntactic Dependencies visit https://spacy.io/api/annotation#dependency-parsing\n",
        "<br>A good explanation of dependencies can be found [here](https://nlp.stanford.edu/software/dependencies_manual.pdf)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sEjPJRuVa-H8",
        "colab_type": "code",
        "outputId": "c3f14940-fe20-4854-af8d-bc13fa28c71b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "spacy.explain('nsubj')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'nominal subject'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jbJfUTkBa-IA",
        "colab_type": "text"
      },
      "source": [
        "#### Other token attributes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6Z4XkL5a-IB",
        "colab_type": "text"
      },
      "source": [
        "|Tag|Description|\n",
        "|:------|:------:|\n",
        "|`.text`|The original word text|\n",
        "|`.lemma_`|The base form of the word|\n",
        "|`.pos_`|The simple part-of-speech tag|\n",
        "|`.tag_`|The detailed part-of-speech tag|\n",
        "|`.shape_`|The word shape – capitalization, punctuation, digits|\n",
        "|`.is_alpha`|Is the token an alpha character?|\n",
        "|`.is_stop`|Is the token part of a stop list, i.e. the most common words of the language?|"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Kac3nFfa-IC",
        "colab_type": "text"
      },
      "source": [
        "## Named Entity Recognition\n",
        "\n",
        "NER introduces another layer of context. The spaCy language model recognizes that certain tokens represent for example locations or organizations. \n",
        "https://spacy.io/usage/linguistic-features#named-entities"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pU6adfHVa-ID",
        "colab_type": "code",
        "outputId": "3f1ab608-e576-446e-a70e-c89b98d9fa38",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        }
      },
      "source": [
        "ner = nlp(u'Apple to build a Hong Kong factory for $6 million')\n",
        "\n",
        "for token in ner:\n",
        "    print(token.text, end=' | ')\n",
        "\n",
        "print('\\n----')\n",
        "\n",
        "for ent in ner.ents:\n",
        "    print(ent.text+' - '+ent.label_+' - '+str(spacy.explain(ent.label_)))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Apple | to | build | a | Hong | Kong | factory | for | $ | 6 | million | \n",
            "----\n",
            "Apple - ORG - Companies, agencies, institutions, etc.\n",
            "Hong Kong - GPE - Countries, cities, states\n",
            "$6 million - MONEY - Monetary values, including unit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7T6_E1SZa-IH",
        "colab_type": "text"
      },
      "source": [
        "We'll also see how spaCy can interpret the tokens combined `$6 million` as referring to ***money***."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dRVTBqXa-II",
        "colab_type": "text"
      },
      "source": [
        "#### Visualizing NER"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Yoa58j6a-IK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy import displacy"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tk_qLD-Sa-IO",
        "colab_type": "code",
        "outputId": "319d6d12-b00f-4cb4-da62-1d5aeeeba387",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "doc = nlp(u'By 2010 standards, the iPad was thin—half an inch thin—and weighed 1.5 pounds. It had a capacitive multitouch display, ran on Apple’s custom A4 chip, and offered 10 hours of battery life, something that would win it praise in early reviews. WIRED’s review noted that watching video on it was “terrific,” as was reading on it, and that the iPad was well-positioned as a gaming platform. But the iPad was also hamstrung in its earliest incarnation. It didn’t have a camera, it didn’t support multitasking, the Safari browsing experience was limited, and the virtual keyboard came with a learning curve')\n",
        "displacy.render(doc, style='ent', jupyter=True)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div class=\"entities\" style=\"line-height: 2.5; direction: ltr\">By \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
              "    2010\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">DATE</span>\n",
              "</mark>\n",
              " standards, the iPad was thin—\n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
              "    half an inch\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
              "</mark>\n",
              " thin—and weighed \n",
              "<mark class=\"entity\" style=\"background: #e4e7d2; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
              "    1.5 pounds\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">QUANTITY</span>\n",
              "</mark>\n",
              ". It had a capacitive multitouch display, ran on \n",
              "<mark class=\"entity\" style=\"background: #7aecec; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
              "    Apple\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">ORG</span>\n",
              "</mark>\n",
              "’s custom \n",
              "<mark class=\"entity\" style=\"background: #bfeeb7; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
              "    A4\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">PRODUCT</span>\n",
              "</mark>\n",
              " chip, and offered \n",
              "<mark class=\"entity\" style=\"background: #bfe1d9; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
              "    10 hours\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">TIME</span>\n",
              "</mark>\n",
              " of battery life, something that would win it praise in early reviews. WIRED’s review noted that watching video on it was “terrific,” as was reading on it, and that the iPad was well-positioned as a gaming platform. But the iPad was also hamstrung in its earliest incarnation. It didn’t have a camera, it didn’t support multitasking, the \n",
              "<mark class=\"entity\" style=\"background: #ff9561; padding: 0.45em 0.6em; margin: 0 0.25em; line-height: 1; border-radius: 0.35em; box-decoration-break: clone; -webkit-box-decoration-break: clone\">\n",
              "    Safari\n",
              "    <span style=\"font-size: 0.8em; font-weight: bold; line-height: 1; border-radius: 0.35em; text-transform: uppercase; vertical-align: middle; margin-left: 0.5rem\">LOC</span>\n",
              "</mark>\n",
              " browsing experience was limited, and the virtual keyboard came with a learning curve</div>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RMaxa10aa-IS",
        "colab_type": "text"
      },
      "source": [
        "#### Visualizing dependency parser"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JKdZryjOa-IT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = nlp(u'Apple is going to build a U.K. factory for $6 million.')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OvZ56XPXa-IY",
        "colab_type": "code",
        "outputId": "0998475e-4600-4325-86e1-67f673b07b59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "displacy.render(doc, style='dep', jupyter=True, options={'distance': 90})"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<svg xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\" xml:lang=\"en\" id=\"44de8c2a0da14d338d9df90d2d283251-0\" class=\"displacy\" width=\"1130\" height=\"317.0\" direction=\"ltr\" style=\"max-width: none; height: 317.0px; color: #000000; background: #ffffff; font-family: Arial; direction: ltr\">\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"50\">Apple</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"50\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"140\">is</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"140\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"230\">going</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"230\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"320\">to</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"320\">PART</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"410\">build</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"410\">VERB</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"500\">a</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"500\">DET</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"590\">U.K.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"590\">PROPN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"680\">factory</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"680\">NOUN</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"770\">for</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"770\">ADP</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"860\">$</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"860\">SYM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"950\">6</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"950\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<text class=\"displacy-token\" fill=\"currentColor\" text-anchor=\"middle\" y=\"227.0\">\n",
              "    <tspan class=\"displacy-word\" fill=\"currentColor\" x=\"1040\">million.</tspan>\n",
              "    <tspan class=\"displacy-tag\" dy=\"2em\" fill=\"currentColor\" x=\"1040\">NUM</tspan>\n",
              "</text>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-44de8c2a0da14d338d9df90d2d283251-0-0\" stroke-width=\"2px\" d=\"M70,182.0 C70,92.0 220.0,92.0 220.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-44de8c2a0da14d338d9df90d2d283251-0-0\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">nsubj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M70,184.0 L62,172.0 78,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-44de8c2a0da14d338d9df90d2d283251-0-1\" stroke-width=\"2px\" d=\"M160,182.0 C160,137.0 215.0,137.0 215.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-44de8c2a0da14d338d9df90d2d283251-0-1\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M160,184.0 L152,172.0 168,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-44de8c2a0da14d338d9df90d2d283251-0-2\" stroke-width=\"2px\" d=\"M340,182.0 C340,137.0 395.0,137.0 395.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-44de8c2a0da14d338d9df90d2d283251-0-2\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">aux</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M340,184.0 L332,172.0 348,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-44de8c2a0da14d338d9df90d2d283251-0-3\" stroke-width=\"2px\" d=\"M250,182.0 C250,92.0 400.0,92.0 400.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-44de8c2a0da14d338d9df90d2d283251-0-3\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">xcomp</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M400.0,184.0 L408.0,172.0 392.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-44de8c2a0da14d338d9df90d2d283251-0-4\" stroke-width=\"2px\" d=\"M520,182.0 C520,92.0 670.0,92.0 670.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-44de8c2a0da14d338d9df90d2d283251-0-4\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">det</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M520,184.0 L512,172.0 528,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-44de8c2a0da14d338d9df90d2d283251-0-5\" stroke-width=\"2px\" d=\"M610,182.0 C610,137.0 665.0,137.0 665.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-44de8c2a0da14d338d9df90d2d283251-0-5\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M610,184.0 L602,172.0 618,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-44de8c2a0da14d338d9df90d2d283251-0-6\" stroke-width=\"2px\" d=\"M430,182.0 C430,47.0 675.0,47.0 675.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-44de8c2a0da14d338d9df90d2d283251-0-6\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">dobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M675.0,184.0 L683.0,172.0 667.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-44de8c2a0da14d338d9df90d2d283251-0-7\" stroke-width=\"2px\" d=\"M430,182.0 C430,2.0 770.0,2.0 770.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-44de8c2a0da14d338d9df90d2d283251-0-7\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">prep</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M770.0,184.0 L778.0,172.0 762.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-44de8c2a0da14d338d9df90d2d283251-0-8\" stroke-width=\"2px\" d=\"M880,182.0 C880,92.0 1030.0,92.0 1030.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-44de8c2a0da14d338d9df90d2d283251-0-8\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">quantmod</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M880,184.0 L872,172.0 888,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-44de8c2a0da14d338d9df90d2d283251-0-9\" stroke-width=\"2px\" d=\"M970,182.0 C970,137.0 1025.0,137.0 1025.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-44de8c2a0da14d338d9df90d2d283251-0-9\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">compound</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M970,184.0 L962,172.0 978,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "\n",
              "<g class=\"displacy-arrow\">\n",
              "    <path class=\"displacy-arc\" id=\"arrow-44de8c2a0da14d338d9df90d2d283251-0-10\" stroke-width=\"2px\" d=\"M790,182.0 C790,47.0 1035.0,47.0 1035.0,182.0\" fill=\"none\" stroke=\"currentColor\"/>\n",
              "    <text dy=\"1.25em\" style=\"font-size: 0.8em; letter-spacing: 1px\">\n",
              "        <textPath xlink:href=\"#arrow-44de8c2a0da14d338d9df90d2d283251-0-10\" class=\"displacy-label\" startOffset=\"50%\" side=\"left\" fill=\"currentColor\" text-anchor=\"middle\">pobj</textPath>\n",
              "    </text>\n",
              "    <path class=\"displacy-arrowhead\" d=\"M1035.0,184.0 L1043.0,172.0 1027.0,172.0\" fill=\"currentColor\"/>\n",
              "</g>\n",
              "</svg>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ecjPzXn1a-Ib",
        "colab_type": "text"
      },
      "source": [
        "If the arches of dependecy parser do not appear on the visualization, in a new cell run `displacy.serve(doc, style='dep')` and then open new browser page and type: `http://127.0.0.1:5000/`\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hNj1CgXRa-Ic",
        "colab_type": "text"
      },
      "source": [
        "## Lemmatization and stemming\n",
        "\n",
        "`Stemming` is a proces of reducing inflected words to their word stem. Here, \"boat\" would be the stem for [boat, boater, boating, boats]. However, in languages with many exceptions we need more sophisticated methods to perform proper stemming. spaCy does not include a stemmer, inbsted it relies entirely on the lemmatization.\n",
        "<br><br>\n",
        "`Lemmatization` on the other hand applies morphological analysis to the word and considers full vocabulary of the language. As a result, the lemma of `was` is be, `better` is good and so on."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D43NHA6_a-Ie",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "doc = nlp(u\"Running was the only thing he could think of while playing with knives\")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WEniSsWAa-Ii",
        "colab_type": "code",
        "outputId": "6412aff7-a30a-48e6-ef9e-b093fd05bc2a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        }
      },
      "source": [
        "for token in doc:\n",
        "    print(f'{token.text:{12}} {token.lemma_:{12}} {token.pos_:{8}} {spacy.explain(token.tag_)}')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running      run          VERB     verb, gerund or present participle\n",
            "was          be           VERB     verb, past tense\n",
            "the          the          DET      determiner\n",
            "only         only         ADJ      adjective\n",
            "thing        thing        NOUN     noun, singular or mass\n",
            "he           -PRON-       PRON     pronoun, personal\n",
            "could        could        VERB     verb, modal auxiliary\n",
            "think        think        VERB     verb, base form\n",
            "of           of           ADP      conjunction, subordinating or preposition\n",
            "while        while        ADP      conjunction, subordinating or preposition\n",
            "playing      play         VERB     verb, gerund or present participle\n",
            "with         with         ADP      conjunction, subordinating or preposition\n",
            "knives       knife        NOUN     noun, plural\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nrFVejF7a-In",
        "colab_type": "text"
      },
      "source": [
        "## Stop words\n",
        "\n",
        "Certain words appear so often in language that they do not require tagging. These words are called `stop words` and we usually filter them out from the processed text. spaCy and other NLP libraries contain inbuilt lists of stop words that are ready for usage. NB stop words list can be modified. spaCy contains 326 stopwords."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lxMxxX0ga-Io",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#print(nlp.Defaults.stop_words)\n",
        "#len(nlp.Defaults.stop_words)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DOXTQq5Da-Ir",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# check if a word is a stop word\n",
        "nlp.vocab['me'].is_stop\n",
        "\n",
        "# add a stop word\n",
        "nlp.Defaults.stop_words.add('macaroni')\n",
        "\n",
        "# set the stop_word tag on the lexeme\n",
        "nlp.vocab['macaroni'].is_stop = True\n",
        "\n",
        "# remove the word from the list\n",
        "nlp.Defaults.stop_words.remove('macaroni')\n",
        "\n",
        "# remove the stop_word tag from the lexeme\n",
        "nlp.vocab['macaroni'].is_stop = False"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvF8JPwqa-Iv",
        "colab_type": "text"
      },
      "source": [
        "References: <br/>\n",
        "1.Wikipedia"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qpae-m_Aa-Iw",
        "colab_type": "text"
      },
      "source": [
        "# 2. Word embeddings \n",
        "\n",
        "In a nutshell word embeddings or word vectors are numerical representation of text. Embeddings are capable of capturing the context of a word within a document and provide a broader meaning.\n",
        "\n",
        "`You shall know a word by the company it keeps` said by a famous British linguist John Rupert Firth represent this idea, meaning that the words in part determined by its collocations. In that way, if we represent words in a multidimensional space the words similar to each like `car` and `bike` other will have closer values. Cosine similarity is used to calculate the distance between the vectors - and it is a measure how similar the words are (0:1)\n",
        "\n",
        "Mostly used models: Word2Vec (SkipGram and CBOW algorithms) and GloVe.\n",
        "\n",
        "Before feeding the text to any machine learning model we first need to convert text strings into numbers.  "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E39qk0CMa-Iy",
        "colab_type": "text"
      },
      "source": [
        "#### Word embeddings with spaCy"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZZAHie2a-Iz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# We load the large english language model - that was trained on OntoNotes - large corpus comprising various genres \n",
        "# of text (news, conversational telephone speech, weblogs, usenet newsgroups, broadcast, talk shows). \n",
        "# With GloVe vectors trained on CommonCrawl - 685k unique vectors (300 dimensions)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3joqt8Dqa-I3",
        "colab_type": "code",
        "outputId": "7213e287-5701-40cf-cb5d-cfd05ec402bc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# acces vector a word\n",
        "nlp('car').vector\n",
        "\n",
        "# shape o a word vector\n",
        "nlp('car').vector.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(300,)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cLzqUBQka-I7",
        "colab_type": "code",
        "outputId": "5ffbc733-3538-4574-8988-fbd326b92fbb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "nlp('car').similarity(nlp('vehicle'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7667538336145884"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "01as_H1ba-I-",
        "colab_type": "text"
      },
      "source": [
        "# 3. Topic modelling"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y-kQP3I_a-I_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Download dataset from: https://www.kaggle.com/snap/amazon-fine-food-reviews"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AI77VbWTa-JF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "B-b-zOdBa-JJ",
        "colab_type": "code",
        "outputId": "b36aeeba-03f1-4ed9-9b60-340cc94dcf93",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 394
        }
      },
      "source": [
        "reviews = pd.read_csv('Reviews.csv')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-1ab55d4d5c28>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mreviews\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Reviews.csv'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36mparser_f\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[1;32m    683\u001b[0m         )\n\u001b[1;32m    684\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 685\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    686\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    687\u001b[0m     \u001b[0mparser_f\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    455\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    456\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    893\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"has_index_names\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 895\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    896\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, engine)\u001b[0m\n\u001b[1;32m   1133\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"c\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1134\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"c\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1135\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1136\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1137\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"python\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/pandas/io/parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, src, **kwds)\u001b[0m\n\u001b[1;32m   1915\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"usecols\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1916\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1917\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1918\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1919\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;32mpandas/_libs/parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[0;34m()\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] File b'Reviews.csv' does not exist: b'Reviews.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5bIPZ0aLa-JM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews.tail()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1IB-BUla-JQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dnl5INQda-JU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews['Text'][1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9K5CfSDha-JY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews['Text'][200]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piaypNbza-Jb",
        "colab_type": "text"
      },
      "source": [
        "## Text preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mbq-pkzZa-Jc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gJfHPfnBa-Jg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews.dropna(inplace=True)\n",
        "reviews.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U_emscrQa-Jj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create a subset of df in order to improve performance\n",
        "#subset = reviews.Text[:10000]\n",
        "subset = reviews.Text[:1000]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubU4dyuca-Jn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "subset"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7bZYX206a-Jr",
        "colab_type": "text"
      },
      "source": [
        "### Removing stopwords"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fv4XcBR6a-Jr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from spacy.lemmatizer import Lemmatizer\n",
        "from spacy.lang.en.stop_words import STOP_WORDS\n",
        "from spacy.lang.en import English\n",
        "import re\n",
        "from tqdm import tqdm_notebook as tqdm\n",
        "from collections import defaultdict "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7tjHcwh3a-Jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# cleaning function for removing stopwords and creating lemma\n",
        "def cleaning(doc):\n",
        "    txt = [token.lemma_ for token in doc if not token.is_stop]\n",
        "    return txt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mAN4VPpma-Jy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# example of a 'dirty' review before processing\n",
        "subset[200]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mvgXiPzUa-J4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# lowercase the words and remove all html tags and store the results in remove_html_tags\n",
        "remove_html_tags = [re.sub(re.compile('<.*?>'), '', str(row)).lower() for row in subset]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAUbdMJea-J8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print results after removing html tags\n",
        "remove_html_tags[200]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVLn7OyJa-J_",
        "colab_type": "text"
      },
      "source": [
        "Results you should receive: <br>\n",
        "`\"even with small containers, they don't fill them up.  these little tins are less than half filled and at the price charged it seems a rip-off. is there some exotic ingredient as costly as gold contained in those tiny squares?  or how about the cereal ploy, they were filled at the factory but settled in transport.can manufacturers be honest in their dealings?\"`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TzO34rTQa-KA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# remove all non-alphabetic characters and store in remove_non_alpha\n",
        "remove_non_alpha = [re.sub(\"[^A-Za-z']+\", ' ', row) for row in remove_html_tags]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BJXWP4vQa-KE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# print the results after removing non-alphabetic characters\n",
        "remove_non_alpha[200]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NvbLeuOna-KH",
        "colab_type": "text"
      },
      "source": [
        "Results you should get: <br>\n",
        "`\"even with small containers they don't fill them up these little tins are less than half filled and at the price charged it seems a rip off is there some exotic ingredient as costly as gold contained in those tiny squares or how about the cereal ploy they were filled at the factory but settled in transport can manufacturers be honest in their dealings \"`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5cWOG-W9a-KI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# apply the cleaning function to the\n",
        "txt = [cleaning(doc) for doc in nlp.pipe(remove_non_alpha, batch_size = 1000, n_threads = -1)]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "S8qb6ORRa-KN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(txt[200])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oFz3T-5wa-KQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "reviews['Text'][200]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N7N7w_0ja-KT",
        "colab_type": "text"
      },
      "source": [
        "Install gensim via anaconda `conda install -c conda-forge gensim`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l10sR3-4a-KU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "\n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "from gensim.models.ldamodel import LdaModel"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCNUwoH0a-KY",
        "colab_type": "text"
      },
      "source": [
        "For full documentation go to: <br> `https://radimrehurek.com/gensim/models/ldamodel.html`<br> `https://radimrehurek.com/gensim/corpora/dictionary.html`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZwH5GKJa-KY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Creates a dictionary, which is a mapping of word IDs to words.\n",
        "id2word = corpora.Dictionary(txt)\n",
        "\n",
        "# Turns each document into a bag of words - containing how many times each word (word id) occured within a document\n",
        "corpus = [id2word.doc2bow(doc) for doc in txt]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RH5Q0DMma-Kf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(id2word[19])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uEViqu1Aa-Kj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(corpus[1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ziYvOybDa-Km",
        "colab_type": "text"
      },
      "source": [
        "### Bag of words : occurences or a word within a document. BoW disregards all informatio about the word meaning or word order. It simply counts how many occurences of a word is there in each document"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7AGTs4sFa-Km",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=5, \n",
        "                                           random_state=42,\n",
        "                                           #update_every=1,\n",
        "                                           #passes=10,\n",
        "                                           alpha=.1, #distribution of the number of topics per document\n",
        "                                           chunksize=100,\n",
        "                                           per_word_topics=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTOeWTa5a-Kp",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pprint import pprint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GD3P2ZYga-Ks",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "pprint(lda_model.print_topics(num_words=10))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O89UsRIUa-Kv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Coherence score give an approximation of how good the topics are, it determines the optimal number of topics.\n",
        "# So, the higher the score the better : 0 < x < 1\n",
        "\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=txt, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IOD739Xka-Ky",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# source: https://datascienceplus.com/evaluation-of-topic-modeling-topic-coherence/\n",
        "def compute_coherence_values(dictionary, corpus, texts, limit, start=2, step=3):\n",
        "    \"\"\"\n",
        "    Compute c_v coherence for various number of topics\n",
        "\n",
        "    Parameters:\n",
        "    ----------\n",
        "    dictionary : Gensim dictionary\n",
        "    corpus : Gensim corpus\n",
        "    texts : List of input texts\n",
        "    limit : Max num of topics\n",
        "\n",
        "    Returns:\n",
        "    -------\n",
        "    model_list : List of LDA topic models\n",
        "    coherence_values : Coherence values corresponding to the LDA model with respective number of topics\n",
        "    \"\"\"\n",
        "    coherence_values = []\n",
        "    model_list = []\n",
        "    for num_topics in range(start, limit, step):\n",
        "        model=LdaModel(corpus=corpus, id2word=dictionary, num_topics=num_topics)\n",
        "        model_list.append(model)\n",
        "        coherencemodel = CoherenceModel(model=model, texts=texts, dictionary=dictionary, coherence='c_v')\n",
        "        coherence_values.append(coherencemodel.get_coherence())\n",
        "\n",
        "    return model_list, coherence_values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XA-tZW8Aa-K0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# source https://datascienceplus.com/evaluation-of-topic-modeling-topic-coherence/\n",
        "model_list, coherence_values = compute_coherence_values(dictionary=id2word, corpus=corpus, texts=txt, start=2, limit=40, step=6)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MBq1jOHfa-K8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Show graph\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "limit=40; start=2; step=6;\n",
        "x = range(start, limit, step)\n",
        "plt.plot(x, coherence_values)\n",
        "plt.xlabel(\"Num Topics\")\n",
        "plt.ylabel(\"Coherence score\")\n",
        "plt.legend((\"coherence_values\"), loc='best')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzK2PKYBa-LA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# conda install -c conda-forge pyldavis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X40edDzDa-LD",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from pyLDAvis import gensim as pyLDAvis_gensim\n",
        "import pickle \n",
        "import pyLDAvis"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uhK-lA_za-LF",
        "colab_type": "text"
      },
      "source": [
        "The visualization below, will allow you to compare topics and see what is the distribution of words per topics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sQno97xUa-LG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "%%time\n",
        "\n",
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "\n",
        "vis = pyLDAvis_gensim.prepare(lda_model, corpus, id2word, sort_topics=True)\n",
        "#lda_display = pyLDAvis.gensim.prepare(lda, corpus, dictionary, sort_topics=False)\n",
        "pyLDAvis.display(vis)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jONZRnBDa-LJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}